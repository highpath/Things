# CNN Basics - Convolution

## Convolutional Neural Network
* Most widely used for image classification
* Generally, it consists of convolution layer, pooling layer and fully-connected layer
* Convolution, Pooling layer - feature extraction
: 특징을 뽑아내는 것.
* Fully-connected layer - classification
: 판단하는 역할

## 2D Convolution Layer
:이미지를 받을 때 2D Convolution Layer 많이 사용

입력의 하나 예 : 32*32*3 image
height 32 * width 32 * channel 3
channel 3 -> 보통 RGB, 흑백인 경우 channel 1

channel 이미지가 아닐 경우 앞쪽 이전 출력의 feature를 받을 때 큰 숫자가 된다.

Filters always extend the full channel of the input volume

convolution c채널이 필터의 채널과 같게 된다.

75개 숫자.
-> 필터가 놓이면 75숫자들 끼리 곱한 다음에 더해서 

1 number : the result of taking a dot product between the filter and a samll 5*5*3 chunk of the image (i.e.5*5*3 = 75-dimensional dot product + bias)

dot product : 내적 연산

연산하고 필터 한칸 옴겨서 연산하고, 다하면 내려가서 연산하고, 맨 오른쪽 아래까지 연산.
그 출력들을 모으면 한장의 이미지 같은 출력이 나옴.
28*28*1

Feature map
Activation map 이라고 부름
예를 들어 첫번째 필터는 뾰족한 부분을 찾아냄, 두번째 필터는 물을 찾는 필터.
6장을 쓰면 channel 이 6이 된다.

output feature map 채널 수 = 이 컨벌루션 레이어에 사용한 필터 개수

filter 채널 수 = input feature map 채널 수

### Computation

* 1x1 + 1x0 + 1x1 + 0x0 + 1x1 + 1x0 + 0x1 + 0x0 + 1x1 = 4

### Multi Channel, Many Filters

### 4D Tensors

미니 배치 학습법
: 이미지, 데이터를 한 개만 사용하지 안혹 여러개를 동시에 사용해서 학습하는 것

미니배치 개수 N개

-> Input feature maps, output featuremaps = 4D

Tensorflow 코드를 작성할 때도 이렇게 모든 입력과 출력은 4차원의 형태로 한다.

## Options of Convolution
* Stride - How far to go to the right or the bottom to perform the next convolution
: 몇 칸 옆으로 이동할 건지

ex) 7x7 input, 3x3 convolution filter with stride 2 -> 3x3 output

* Zero Padding
: 하는 이유는 처음에 32x32 이미지를 넣었을 때 5x5 컨벌루션 연산을 하고 나면 28x28 짜리 출력이 나온다.

패딩 안하면 이미지가 줄어드는데 이러면 layer를 깊게 쌓는데 지장이 있다.

in general, common to see CONV layers with stride 1, filters of size FxF, and zero-padding with (F-1)/2. (will preserve size spatially)
e.g. F = 3 => zero pad with 1

* ReLU
: 컨벌루션 연산이 끝나면 activation function을 통과시키는 데 가장 많이 쓰는 게 ReLU.
음수는 0으로 바꿔주고 양수는 그대로 통과

## tf.keras.layers.Conv2D

* filters : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).
컨벌루션 필터의 수. 아웃풋 피쳐맵의 채널을 몇으로 할 건지

* kernel_size : An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.
컨벌루션 필터를 몇 곱하기 몇으로 할 건지.
3x3 이면 3만 써도 되고
(3,3) 도 되고 [3,3] 도 되고

* strides : An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatiable with specifying dilation_rate value != 1.
스트라이드를 뭘로 할 건지

* padding : one of "valid" or "same" (case-intensitive).


* data_format : A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_foramt value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be "channels_last".

channel_last 가 디폴트. 이 경우 배치, 하이트, 위뜨, 채널 순서로 구성. 배치는 미니 배치 사이즈. 이 순서를 지켜줘야 함

### Padding - SAME vs VALID
Valid : 패딩을 안하는 거
Same : 입력과 출력이 같아지도록.
Pstart : 왼쪽과 위쪽에 패딩하는 개수
Pend : 오른쪽과 아래쪽에 패딩하는 개수

s = stride, i = input feature map의 가로나 세로 사이즈
f = filter의 가로나 세로 사이즈
」: 버림, 「 : 올림
오른쪽이나 아래쪽에 한 줄이 더 패딩 되거나 모든 방향에 똑같이 패딩이 되거나

* activation : activation function to use. If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).
: ReLU 같은 걸 쓰게 되면 여기다 하면 된다.

* use_bias = Boolean, whether the layer uses a bias vector.
bias를 쓸건지 에 대한 부분

* kernel_initializer : Initializer for the kernel weights matrix.
* bias_initializer : Initializer for the bias vector.

-> 컨벌루션 필터가 어떻게 initialize 해줄 것인지. 보통 랜덤하게 initialize 하는데 어떤 방법을 쓸건지

* kernel_regularizer : Regularizer function applied to the kernel weights matrix.

* bias_regularizer : Regularizer function applied to the bias vector.

- 앞에서 배운  L2 Regularization 방법 같은 거


* kernel dimension : {height, width, in_channel, out_channel}

케라스 밑에 레이아스 같은 high level API를 쓸 때에는, 별로 쓸 일이 없긴 한데, 실제로 컨벌루션 필터 커널의 디멘션도 4차원을 갖는다고 했잖아요?
앞에서 input fmap 의 배치, 하이트, 위드, 채널 순서와 다르다.
필터는 4차원인데 헤이트, 위드, 인풋채널, 아웃풋채널
123 - > 컨벌루션 필터에 대한 거
4 -> 컨벌루션 필터의 개수