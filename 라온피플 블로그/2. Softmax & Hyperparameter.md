# Softmax & Hyperparameter

## Activation Function

## Softmax Function
Multiclass Classification 문제에서는 Softmax function이 대표적인 Activation function으로 쓰인다.


Multiclass Classification : the problem of classifying instances into one of three or more classes

특징 : 클래스의 결과 값은 0~1로 정규화되며, 모든 클래스의 결과 값의 합은 1이다.
따라서 클래스의 결과 값은 각 클래스에 해당할 확률과 같다.

## Hyperparameter
Deep Learning은 weight 값을 스스로 학습하여 최적의 신경망을 스스로 찾아내지만, 실제로 학습 시킬 때에는 사람이 직접 튜닝해 주어야 할 다양한 변수가 있습니다.

1. Learning rate
Learning rate는 결과의 오차를 학습에 얼마나 반영할 지를 결정하는 변수입니다.

2. Cost function
Cost function은 입력에 따른 기대 값과 실제 값의 차이를 계산하는 함수입니다.

- Mean Squre Error (평균 제곱 오차)
- Cross-Entropy Error (교차 엔트로피 오차)

3. Regularization parameter
Overfitting의 문제를 피하기 위해 L1, L2 regularization 방법을 사용할 수 있습니다.

Regularization(정규화)를 하지 않았을 때는 그림 a와 같이 overfitting 된 결과를 얻을 수 있으나, Regularization 했을 때는 실제 데이터 분포에 더 가까운 결과를 얻을 수 있습니다.

### L1 and L2 Regularization
Regularization basically adds the penalty as model complexity increases.
Regularization parameter (lambda) penalizes all the parameters except intercept so that model generalizes the data and won't overfit.

In order to create less complex (parsimonious) model when you have a large number of features in your dataset, some of the Regularization techniques used to address 

A regression model that uses L1 regularization technique is called Lasso Regression and model which uses L2 is called Ridge Regression.

The key difference between these two is the penalty term.

Ridge regression adds "squared magnitude" of coefficient as penalty term to the loss function.

Here, if lambda is zero then you can imagine we get back OLS

OLS : Ordinary least squares is a type of linear least squares method for estimating the unknown parameters in a linear regression model.

least squares : standard approach in regression analysis to approximate the solution of overdetermined systems (sets of equations in which there are more equations than unknowns) ...

However, if lambda is very large then it will add too much weight and it will lead to under-fitting.

Having said that it's important how lambda is chosen.

This technique works very well to avoid over-fitting issue.

Lasso Regression (Least Absolute Shrinkage and Selection Operator) adds "absolute value of magnitude" of coefficient as penalty term to the loss function.

Again, if lambda is zero then we will get back OLS whereas very large value will make coefficients zero hence it will under-fit.

The key difference between these techniques is that Lasso shrinks the less important feature's coefficient to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.

Traditional methods like cross-validation, stepwise regression to handle overfitting and perform feature selection work well with a small set of features but these techniques are a great alternative when we are dealing with a large set of features.

4. Mini-batch 크기
모든 데이터의 Cost function의 합을 구하려면 데이터가 많을 수록 많은 시간이 걸리며, 그 때문에 데이터 중 일부를 사용하여 가중치를 갱신하여 학습하게 됩니다.

이때, Mini-batch의 크기가 크면 병렬 연산 구조에서 학습 속도를 높일 수 있으며, 크기가 작으면 더 자주 update 할 수 있습니다.

5. Training 반복 횟수
위 그림과 같이 Training 횟수가 너무 많으면 Overfitting 되어 훈련 시 정확도는 높아져도 실제 정확도는 떨어질 수 있습니다.

학습 효율이 떨어지는 시점에서 학습을 종료해야 좋은 결과를 얻을 수 있습니다.

6. Hidden unit의 개수
Hidden layer의 Hidden unit의 개수가 많으면 네트워크로 표현력이 넓어져 더 좋은 성능을 낼 수도 있지만, overfitting 될 수 있는 문제점이 있습니다.

반대로 Hidden Unit의 개수가 너무 적으면 네트워크의 표현력이 줄어들어 학습을 시켜도 Underfitting 될 수 있습니다.

In neural networks, a hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output.

In short, the hidden layers perform nonlinear transformations of the inputs entered into the network.


The closes thing to a formal definition is, a hidden unit takes in a vector/tensor, compute an affine transformation z and then applies an element-wise non-linear function g(z).

7. 가중치 초기화(Weigh initialization)
가중치 초기 값을 잘못 설정하면 학습이 효과를 보지 못할 수 있습니다.

예를 들어 모든 초기 값을 0으로 설정한다면 모든 뉴런이 동일한 결과를 내며, Back propagation 과정에서 동일한 gradient 값을 얻어 모든 파라미터가 동일한 값으로 update 되어 뉴런의 개수가 의미가 없어집니다.

가중치는 보통 입력 데이터 수를 n으로 둘 때 +- 1/root n 의 범위 안에서 랜덤으로 결정합니다.

## Hyperparameter Optimization
위의 다양한 Hyperparameter를 설정하는 방법에는 아래와 같은 방법들이 있습니다.

1. Grid Search
Hyperparameter의 대략적인 범위를 지정하고 일정한 간격으로 값을 선택하여 학습하는 방법입니다.

이 방법은 각 Hyperparameter를 범위 내에서 골고루 테스트 해보는 방법이지만, Hyperparameter가 늘어날수록 그 배수만큼 학습 시간이 늘어나 비효율적입니다.

2. Random Search

대략적인 범위를 지정하고 그 범위 내에서 랜덤하게 값을 선택하여 학습하는 방법입니다.

Grid search는 일정한 간격으로 테스트 하기 때문에 그 간격 사이에 최적의 값이 있을 경우 놓치게 될 수 있습니다.
Random search는 각 Hyperparameter를 전부 랜덤으로 정하기 때문에 Grid search보다 더 다양하게 테스트 할 수 있습니다.

또한 Grid search는 순서대로 테스트하므로 도중에 학습을 그만둘 경우 범위 내의 일부만 테스트 될 가능성이 있지만, Random search는 랜덤하게 선택하므로, 언제 학습을 그만두어도 테스트한 값이 편중되지 않을 수 있습니다.

3. Bayesian optimization

Bayesian optimization은 기존 학습 결과로 Hyperparameter의 사전 분포를 가정하고, 최적의 Hyperparameter로 가정되는 값의 학습 결과를 획득하여 사후 분포를 결정하는 작업을 반복하는 방법입니다.

Hyperparameter에 따른 불확실성과 결과의 기댓값을 종합하여 다음에 학습할 Hyperparameter를 결정하고 그 결과로부터 불확실성과 결과의 기대값을 예측하고 다시 학습할 Hyperparameter를 결정합니다.

복잡한 방법이지만 Random search 보다 빠른 시간 내에 탐색이 가능합니다.



