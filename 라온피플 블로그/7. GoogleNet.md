# CNN 구조 2 - GoogleNet

## CNN의 성능 향상 방법

CNN의 성능을 향상시키기 가장 직접적인 방식은 망의 크기를 늘리는 것입니다.

여기서 망의 크기를 늘린다는 것은 단순하게 망의 layer 수(depth)를 늘리는 것뿐만 아니라, 각 layer에 있는 unit의 수(width)도 늘리는 것을 의미합니다.

특히 ImageNet 데이터와 같이 대용량 데이터를 이용해 학습을 하는 경우는 필수적이라고 할 수 있습니다.

## 깊은 망의 부작용

망이 깊어지면 성능이 높아지지만 2가지 중대한 문제가 발생합니다.

첫 번째, 망이 깊어질 수록 자유 파라미터의 수가 증가하게 되며, 만약 학습에 사용할 데이터 양이 제한적일 경우 망이 overfitting에 빠질 가능성이 높아집니다.

두 번째, 망의 크기가 커지면 그만큼 연산량이 늘어나게 됩니다.

예를 들어, GoogleNet보다 layer 수가 적은 AlexNet의 경우 자유 파라미터 개수가 6,000만 개이고 약 6억 3000만개의 connection으로 이루어져 있어 학습시간이 오래 걸립니다.

이처럼 단순하게 망을 깊게 만든다면, 자유 파라미터 및 connection도 많아지게 되면서 학습은 더욱더 오래 걸리게 됩니다.

## NIN(Network In Network)

GoogleNet에서는 망의 깊이 및 넓이가 모두 커지고, 중간에 분기되는 부분도 있고, Inception이라는 생소한 모듈이 등장합니다.

Inception의 구조를 살펴보기 전에 뼈대가 되는 구조인 Network In Network 을 먼저 살펴보도록 하겠습니다.

NIN은 말 그대로 네트워크 속 네트워크를 뜻합니다.

일반적으로 CNN 구조는 feature extraction(conv + pooling layer)과 classifier(fully connected neural network)로 구성이 됩니다.

NIN 설계자는 CNN의 convolutional layer가 local receptive field에서 feature를 추출해내는 능력은 우수하지만 filter의 특징이 linear하기 때문에 non-linear한 성질을 갖는 feature를 추출하기엔 어려움이 있으므로, 이 부분을 극복하기 위해 feature의 개수를 늘려야 하는 문제에 주목했습니다.

그래서 NIN 설계자는 local receptivce field 안에서 좀 더 feature를 잘 추출할 수 있는 방법들을 연구하였으며 이를 위해 micro neural network를 설계하였습니다.

이들은 convolution을 수행하기 위한 filter 대신에 MLP(Multi-Layer Perceptron)을 사용하여 feature를 추출할 수 있도록 하였습니다.

MLP를 사용하였을 때 장점은 convolution kernel 보다는 non-linear한 성질을 잘 사용할 수 있기 때문에 feature를 추출할 수 있는 능력이 우수하다는 점입니다.

또한 1x1 convolution을 사용해 feature-map을 줄일 수 있도록 하였습니다.

MLPconv layer 3개를 사용한 구조로, NIN 구조가 기존 CNN과 또 다른 점은 CNN 최종단에서 보이는 fully-connected neural network이 없습니다.

fully-connected neural network 대신에 최종단에 Global average pooling을 사용하였고, 이는 앞에서 효과적으로 feature-vector를 추출하였기 때문에, 추출된 vector들에 대한 pooling만으로 충분하다고 주장하고 있습니다.

average pooling만으로 classifier 역할을 할 수 있기 때문에 overfitting의 문제를 회피할 수 있고 연산량이 대폭 줄어드는 이점도 얻을 수 있습니다.

## 1x1 Convolution

1x1 Convolution을 하는 이유는 차원을 줄이는 것으로, Hebbian principle(Neurons that fire together, wire together)에 의해 차원을 줄일 수 있습니다.

1x1 Convolution을 수행하면, 여러 개의 feature-map으로부터 비슷한 성질을 갖는 것들을 묶어낼 수 있고, 결과적으로 feature-map의 숫자를 줄일 수 있으며, 연산량도 줄일 수 있게 되고, 연산량이 줄어드면 망을 더 깊게 할 수 있는 여지가 생기게 됩니다.

## Inception

구글은 인셉션에 대한 개발을 하면서 NIN구조를 많이 참고하였습니다.

Local receptive field에서 더 다양한 feature를 추출하기 위해 여러 개의 convolution을 병렬적으로 활용하려고 하였습니다.

원래 1x1, 3x3, 5x5 Convolution 및 3x3 max pooling을 나란히 놓는 구조를 고안하여 다양한 scale의 feature를 추출하기에 적합한 구조가 되지만 3x3, 5x5 Convolution은 연산량의 관점에서 보면, expensive unit이 됩니다.

그래서 3x3, 5x5 Convolution 앞에 1x1 Convolution을 cascade 구조를 두고, 1x1 Convolution을 통해 feature-map의 개수를 줄이게 되면, feature 추출을 위한 여러 scale을 확보하면서도, 연산량의 균형을 맞출 수 있게 됩니다.

즉, GoogleNet의 22layer까지 깊어질 수 있는 것도 1x1 Convolution을 통해 연산량을 조절할 수 있었기 때문에 깊은 망을 구성할 수 있게 된 것입니다.

NIN에서는 MLP를 이용하여 non-linear feature를 얻어내는 점에 주목을 했지만, fully-connected neural network의 형태이고, 구조적인 관점에서도 그리 익숙하지 못하지만 GoogleNet은 기족의 CNN 구조에서 크게 벗어나지 않으면서도 효과적으로 feature를 추출할 수 있게 되었습니다.

## GoogleNet의 구조

GoogleNet은 총 9개의 인셉션 모듈이 적용이 되었고, 위 그림에서 자세히 유닛을 확인해 보면 파란색은 convolution layer를 의미하고, 빨간색은 max-pooling, 노란색은 Softmax layer, 녹색은 기타 function을 나타냅니다.

빨간색 동그라미는 인셉션 모듈을 나타내고 위에 있는 숫자는 각 단계에서 얻어지는 feature-map의 수를 나타냅니다.

Patch size/stride는 커널의 크기와 stride 간격을 말하고, 최초의 convolution에 있는 7x7/2의 의미는 receptive field의 크기가 7x7인 filter를 2픽셀 간격으로 적용한다는 뜻입니다.

Output size는 얻어지는 feature-map의 크기 및 개수를 나타냅니다.

112x112x64의 의미는 224x224 크기의 이미지에 2픽셀 간격으로 7x7 filter를 적용하여 총 64개의 feature-map이 얻어졌다는 뜻입니다.

Depth는 연속적인 convolution layer의 개수를 의미합니다.

첫 번째 convolution layer는 depth가 1이고 두 번째와 인셉션이 적용되어 있는 부분은 모두 2로 되어 있는 이유는 2개의 convolution을 연속적으로 적용하기 때문입니다.

#1x1 는 1x1 Convolution을 수행한 뒤 얻어지는 feature-map의 개수를 말하고, 첫 번재 인셉션3(a)의 숫자는 64인데 이것은 이전 layer의 192개의 feature-map을 입력으로 받아 64개의 feature-map이 얻어졌다는 뜻입니다.

즉, 192차원이 64차원으로 줄어들게 됩니다.

#3x3 reduce는 3x3 Convolution 앞쪽에 있는 1x1 Convolution을 의미하며 마찬가지로 인셉션 3(a)의 수를 보면 96이 있는데 이것은 3x3 Convolution을 수행하기 전에 192차원을 96차원으로 줄인 것을 의미합니다.

#3x3는 1x1 Convolution에 의해 차원이 줄어든 feature-map에 3x3 Convolution을 적용합니다.

인셉션3(a)의 숫자 128은 최종적으로 1x1 Convolution과 3x3 Convolution을 연속으로 적용하여 128개의 feature-map이 얻어졌다는 뜻입니다.

#5x5 reduce의 해석방법은 #3x3 reduce와 동일합니다.

#5x5의 해석방법은 3x3과 동일하나 #5x5는 좀 더 넓은 영역에 걸쳐있는 feature를 추출하기 위한 용도로 인셉션 모듈에 적용이 되었습니다.

Pool/proj는 max-pooling과 뒤에 오는 1x1 Convolution을 적용한 것을 의미하고, 인셉션 3(a)열의 숫자 32는 max-pooling과 1x1 Convolution을 거쳐 총 32개의 feature-map이 얻어졌다는 뜻입니다.

Params은 해당 layer에 있는 free parameter의 개수를 나타내며, 입출력 feature-map의 수에 비례합니다.

인셉션 3(a)열에 있는 숫자 159k는 총 256개의 feature-map을 만들기 위해 159k의 free-parameter가 적용되었다는 뜻입니다.

Ops는 연산의 수를 나타내고, 연산의 수는 feature-map의 수와 입출력 feature-map의 크기에 비례합니다.

인셉션 3(a)의 단계에서는 총 128M의 연산을 수행합니다

## Auxiliary classifier

googleNet의 블락도를 보면 이전의 CNN 구조에서는 볼 수 없는 구조인 Auxiliary classifier라고 불리는 독특한 유닛이 있습니다.

망이 깊어지면서 생기는 큰 문제 중 하나는 vanishing gradient 문제로 학습 속도가 아주 느려지거나 Overfitting 문제가 발생합니다.

googleNet에서는 이 문제를 극복하기 위해 Auxiliary classifier를 중간 2곳에 두었고, 학습을 할 때는 이 Auxiliary classifier를 이용하여 vanishing gradient 문제를 피하고 수렴을 더 좋게 해주면서 학습결과가 좋게 됩니다.

## Factorizing Convolutions
큰 필터 크기를 갖는 convolution 커널을 인수분해하면, 작은 커널 열 개로 구성된 deep network를 만들 수 있으며, parameter의 수가 줄어들면서 망은 깊어지는 효과를 얻을 수 있습니다.

5x5 convolution은 3x3 에 비해 더 넓은 영역에 걸쳐 있는 특징을 1번에 추출할 수 있지만, 연산량이 많고, 위 그림처럼 5x5 convolution을 2 layer의 3x3 convolution으로 구현한 경우로 free parameter의 수는 5x5 convolution에 비해 28% 절감되는 효과가 발생합니다.

nxn convolution은 1xn 및 nx1로 분해가 가능하며 n이 클수록 파라미터 절감 효과가 커집니다.