# CNN 구조 1 - LeNet, AlexNet, ZFNet

## LeNet

LeNet은 Convolution Neural Network라는 개념을 최초로 개발한 Yann Lecun이 개발한 구조입니다.

LeNet-5 는 아래와 같은 구조를 가지고 있습니다.

Convolution과 Subsampling을 반복적으로 거치면서, 마지막에 Fully-connected Multi-layered Neural Network로 Classification을 수행하고 있습니다.

각 단계를 살펴보도록 하겠습니다.

C1에서는 5x5 Convolution 연산하여 28x28 사이즈의 6개의 feature map을 생성합니다.

5x5의 Convolution kernel에 bias가 더해져, 하나의 feature map을 만드는데 (5x5+1=26)개의 자유 파라미터가 있고, 6개의 feature map을 생성하므로 156개의 자유 파라미터가 있습니다.

S2에서는 Subsampling 하여 feature map의 크기를 14x14로 줄입니다.

Average pooling을 수행하므로 각각의 feature map 마다 weight 1 + bias 1 의 자유 파라미터가 있어 총 12개의 자유 파라미터가 있습니다.

C3에서는 5x5 Convolution 연산하여 10x10 사이즈의 16개의 feature map을 생성합니다.

이 때, 6개의 feature map을 모든 출력에 연결하지 않고, 아래 표와 같이 선택적으로 입력 영상을 골라 출력 영상과 연결합니다.

이렇게 하는 이유는 연결의 symmetry를 깨줌으로써, 처음 convolution으로부터 얻은 6개의 low-level feature가 서로 다른 조합으로 섞이면서 global feature로 나타나기를 기대하기 때문입니다.

Global features describe the entire image, whereas local features describe the image patches (small group of pixels)

이러한 연결로 인해, 이 layer의 자유 파라미터의 개수는 25(kernel) x 60(S2와 C3의 연결 개수) + 16(bias) = 1516개가 됩니다.

S4에서는 Subsampling 하여 feature map의 크기를 5x5로 줄입니다.

S2와 같이 Average pooling을 수행하여 자유 파라미터의 개수는 (2x16=32)개입니다.

C5에서는 5x5 Convolution 연산하여 1x1 사이즈의 120개의 feature map을 생성합니다.

S4의 모든 feature map이 C5의 모든 feature map과 연결되어, 자유 파라미터의 개수는 25(kernel) x 16(S4의 feature map 수) x 120(C5의 feature map 수) + 120(bias) = 48120개가 됩니다.

마지막으로 F6에서 Fully-connected neural network로 C5의 결과를 84개의 unit에 연결시킵니다.

자유 파라미터의 개수는 120(C5) x 84(F6) + 84(bias) = 10164개가 됩니다.

## AlexNet

AlexNet은 ImageNet 영상 데이터 베이스를 기반으로 한 화상 인식 대회인 "ILSVRC 2012"에서 우승한 CNN 구조입니다.

전체적으로 보면 2개의 GPU를 기반으로 한 병렬 구조인 점을 제외하면, LeNet-5와 크게 다르지 않음을 알 수 있습니다.

AlexNet은 5개의 convolution layers와 3개의 fully-connected layers로 구성되어 있으며, 마지막 FC layer는 1000개의 category로 분류하기 위해 활성 함수로 softmax 함수를 사용하고 있습니다.

이러한 설계로 인해 AlexNet은 약 65만개의 뉴런과 6,000만개의 자유 파라미터, 6.3억개의 connection이라는 방대한 CNN 구조를 가지게 되었습니다.

AlexNet의 블록은 표현하는 그림은 위와 같은데, depth는 LeNet에서 feature map의 개수와 같은 의미이며, 각 층의 연산 과정은 동일합니다.

다만 LeNet은 32x32의 1채널 이미지를 사용했지만 AlexNet은 227x227의 3채널 이미지를 사용하여, 그에 따라 convolution layer의 개수, kernel 크기, stride에 차이가 있습니다.

AlexNet의 첫 번째 convolution layer의 kernel의 크기는 11x11x3이며, stride를 4로 적용하여 96개의 feature map을 생성하여, 55x55x96의 출력을 가지게 됩니다.

첫 번째 convolution layer을 거치면서, GPU-1에서는 주로 컬러와 상관 없는 정보를 추출하기 위한 kernel이 학습되고, GPU-2에서는 주로 컬러와 관련된 정보를 추출하기 위한 kernel이 학습됩니다.

첫 번째 convolution layer 다음은 max-pooling으로 27x27x96으로 사이즈를 줄입니다.

두 번째 convolution layer는 5x5 사이즈의 kernel로 연산하여 27x27x256의 이미지를 출력하고, 그 다음에 max-pooling으로 13x13x256으로 사이즈를 줄입니다.

세 번째 convolution layer는 3x3 사이즈의 kernel로 연산하여 13x13x384의 이미지를 출력합니다.

이 때는 두 GPU가 서로의 연산 결과를 섞어서 연산합니다.

네 번째 convolution layer는 3x3 사이즈의 kernel로 연산하여 13x13x384의 이미지를 출력합니다.

다섯 번째 convolution layer는 3x3 사이즈의 kernel로 연산하여 13x13x256의 이미지를 출력하고, max-pooling으로 6x6x256으로 사이즈를 줄입니다.

Convolution layer 연산이 끝나면 두 GPU의 결과를 합쳐 두 층의 Fully-connected layer로 연산하고, 마지막으로 softmax를 통해 1000개의 클래스로 구분됩니다.

AlexNet은 2개의 GPU를 사용한 학습 이외에도 성능, 속도 개선을 위하여 아래와 같은 여러가지 방법을 이용하고 있습니다.

1. ReLU
일반적으로 자주 이용되는 활성함수로 sigmoid 함수나 tanh 함수가 있지만, AlexNet과 같이 크기가 큰 망에서는 학습 속도가 느려지는 단점이 있습니다.

AlexNet에서는 대신에 활성화 함수로 ReLU를 사용하여 학습 속도를 개선하였습니다.

2. Local Response Normalization (LRN)
LRN은 같은 위치의 픽셀에 대해서, 복수의 feature map 간에 정규화를 하는 방법입니다.

이 방법은 실제 세포에서 발생하는 측면 억제(lateral inhibition) 현상과 같은 효과가 있으며, 망의 일반화를 돕는 효과가 있습니다.

AlexNet에서는 LRN을 첫 번째와 두 번째 convolution layer 다음에 적용하고 있습니다.

3. Overlapping Pooling
일반적으로 max pooling을 할 때는 각각 중복되지 않은 영역에서 pooling 합니다.

하지만 AlexNet은 3x3 영역을 2픽셀 단위로 pooling 하여 조금씩 겹치는 부분이 있도록 pooling 하여, overfitting 현상을 개선하였습니다.

4. Data Augmentation
AlexNet은 overfitting을 억제하기 위해 학습 데이터를 증가시키는 방법으로 아래와 같은 방법을 쓰고 있습니다.
- 256x256 이미지에서 랜덤으로 227x227 이미지를 crop
- RGB 채널 값 변화

5. Dropout
Dropout은 Network의 일부를 생략하여 다른 Model을 학습한 것과 같은 효과를 얻어 overfitting을 개선하는 방법입니다.

AlexNet에서는 첫 번째와 두 번째 fully-connected layer에서 Dropout을 적용하고 있습니다.

## ZFNet
ZFNet은 ILSVRC 2012에서 우승한 AlexNet에 이어 ILSVRC 2013에서 우승한 CNN 구조입니다.

ZFNet의 구조 자체는 AlexNet에서 GPU를 하나만 쓰고 일부 convolution layer의 kernel 사이즈와 stride를 일부 조절한 것 뿐입니다.

ZFNet의 논문의 핵심은, ZFNet의 구조 자체보다도 CNN을 가시화하여 CNN의 중간 과정을 눈으로 보고 개선 방향을 파악할 방법을 만들었다는 것에 있습니다.

ZFNet 논문의 Visualizing 기법에 대해 알아보겠습니다.

CNN의 중간 layer의 feature map은 그 자체로는 의미를 알기 어려우므로, 입력 이미지 공간에 mapping하여 분석 할 수 있습니다.

지금까지 알아본 것처럼, CNN은 convolution 계산 후 활성 함수를 통해 featue map을 생성하고, pooling 하여 이미지를 축소 시키는 것을 반복합니다.

그렇다면, 아래 이미지와 같이 그 동작을 반대로 하면 원본 이미지에 mapping 할 수 있는 이미지를 생성할 수 있을 것입니다.

여기서 가장 문제가 되는 것은 max-pooling인데, max-pooling은 이미지를 축소시키는 과정에서 가장 강한 자극만을 전달합니다.

이것을 반대로 할 때는 그 강한 자극이 어디에서 온 자극인지 알 수 없는 문제가 있습니다.

ZFNet 논문의 Visualizing 기법에서는 switch라는 개념을 생각해내어, max-pooling 과정의 가장 강한 자극의 위치를 가지고 있도록 하여, un-pooling 할 때 그 위치를 알 수 있도록 하였습니다.

위 이미지와 같이, 각 레이어의 결과를 Visualizing 하여 CNN이 입력 이미지의 어떤 부분에서 자극을 받고 있는지 눈으로 확인할 수 있습니다.

