# code 예제
## 패키지

- numpy : 행렬이나 일반적으로 대규모 다차원 배열을 쉽게 처리 할 수 있도록 지원하는 파이썬의 라이브러리이다.

- pandas : software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.

- os : This module provides a portable way of using operating system dependent functionality. 

- matplotlib : comprehensive library for creating static, animated, and interactive visulizations in Python.

- sklearn. metrics : this module implements several loss, score, and utility functions to measure classification performance.

- metrics.f1_score(y_true, y_pred, \*[, ...]) : Compute the F1 score, also known as balanced F-score or F-measure

F1 score : a measure of a test's accuracy.

## 데이터 로드

submission = pd.read_csv('data/sample_submission.csv')

train_files = os.listdir('data/train')

<!-- os.listdir(path='.')
Return a list containing the names of the entries in the directory given by path.
The list is in arbitrary order, and does not include the special entries '.' and '..' even if they are present in the directory. -->

train = []
for file in train_files:
    try:
        data = np.load('data/train/'+file).astype('float32')
        train.append(data)
    except:
        continue

<!-- numpy.load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII') -->


# 종류
- RMSLE (Root Mean Square Logarithmic Error)

- MSPE (mean squared prediction error)

- 강화 학습
: 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법

- MAE : Mean absolute error. A meausre of errors between paired observations expressing the same phenomenon.

- f1 score : 

# 개발 환경

1. 구축할 기술 스택
    - Window10 64-bit
    - Python 3.7 (아나콘다 conda 4.7.12)
    - TensorFlow GPU 2.0
    - NVIDIA GPU drivers 418.x or higher
    - Visual Studio 2019
    - cuDNN v7.6.5
    - LightGBM, XGBoost

아나콘다는 파이썬 기반의 범용 패키지로 머신러닝을 비롯한 과학 계산용도로 인기가 좋다.

아나콘다 대신 Python을 직접 설치할 수도 있지만 필요한 패키지를 전부 찾아 pip 명령어로 별도로 설치해야 하거나, XGBoost 등 윈도우에서 설치가 까다로운 패키지들도 쉽게 설치할 수 있기 때문에 본 장에서는 아나콘다를 설치한다.

더욱이 텐서플로는 공식적으로 윈도우에서 아나콘다 배포판을 설치할 것을 권장한다.

cuDNN is a GPU-accelerated library of primitives for deep neural networks.

cuDNN provieds highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers.

LightGBM is a gradient boosting framework that uses tree based learning algorithms.
It is designed to be distributed and efficient with the following advantages:

- Faster training speed and higher efficiency.
- Lower memory usage.
- Better accuracy.
- Support of parallel and GPU learning.
- Capable of handling large-scale data.

XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable.

It implements machine learning algorithms under the Gradient Boosting framework.

